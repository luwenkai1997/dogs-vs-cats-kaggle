{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dogs vs Cats",
   "id": "8350c3b29f0e44a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 1: Setting up the Environment",
   "id": "10783ae453d4a4d5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T06:34:42.480520Z",
     "start_time": "2024-11-13T06:34:06.095852Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install torch torchvision matplotlib",
   "id": "3406284d9561ac7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\r\n",
      "  Downloading torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m150.8/150.8 MB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting torchvision\r\n",
      "  Downloading torchvision-0.17.2-cp311-cp311-macosx_10_13_x86_64.whl (1.7 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/1.7 MB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: matplotlib in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (3.7.1)\r\n",
      "Requirement already satisfied: filelock in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from torch) (3.9.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from torch) (4.12.1)\r\n",
      "Requirement already satisfied: sympy in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from torch) (1.11.1)\r\n",
      "Requirement already satisfied: networkx in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from torch) (2.8.4)\r\n",
      "Requirement already satisfied: jinja2 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from torch) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from torch) (2023.3.0)\r\n",
      "Requirement already satisfied: numpy in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from torchvision) (1.24.3)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from torchvision) (10.3.0)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.0.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from matplotlib) (23.2)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/luwenkai/anaconda3/lib/python3.11/site-packages (from sympy->torch) (1.2.1)\r\n",
      "Installing collected packages: torch, torchvision\r\n",
      "Successfully installed torch-2.2.2 torchvision-0.17.2\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 2: Import Necessary Libraries",
   "id": "c0f52baa07bd2052"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T06:35:14.696318Z",
     "start_time": "2024-11-13T06:34:53.487218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "3b3804ab1c9a2bd9",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Step 3: Data Preparation",
   "id": "c1f0d439a192f5d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.1 Define Data Transformations: Use transformations to resize images, normalize pixel values, and apply data augmentation for the training set to make the model more robust.",
   "id": "bc432ce7dae89468"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T06:38:07.533992Z",
     "start_time": "2024-11-13T06:38:07.527596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ])\n",
    "}"
   ],
   "id": "7c8bbc074a8ec55c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 3.2 Load Data",
   "id": "6529e853c99b05c4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data_dir = \"data/train\"\n",
    "dataset = datasets.ImageFolder(data_dir, transform=data_transforms['train'])\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n"
   ],
   "id": "fb93affc725ea842"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "caae8325e3939cb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "429404d4a2f6ef1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c6e82be2bd3a19d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "698654e045345e38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f895b3d8e403c5ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4da4b3c9064f8901"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "43d7f217dd3aad56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b24e7deb01ac0ad3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
